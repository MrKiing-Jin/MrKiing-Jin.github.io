<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>深度学习-pytorch-CNN网络实践 | 蜡笔小金QAQ的个人主页</title><meta name="keywords" content="学习"><meta name="author" content="蜡笔小金QAQ"><meta name="copyright" content="蜡笔小金QAQ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="CNN网络实践引入包12345678import torch.nn as nnimport torch.nn.functional as Fimport numpy as npimport torchfrom torch.utils.data import Datasetimport pandas as pd%matplotlib inline  读入数据集onehot编码 iloc()函数  1">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习-pytorch-CNN网络实践">
<meta property="og:url" content="http://example.com/2022/08/20/%E4%B8%87%E8%81%AA%E8%80%81%E5%B8%88%E9%A1%B9%E7%9B%AE/index.html">
<meta property="og:site_name" content="蜡笔小金QAQ的个人主页">
<meta property="og:description" content="CNN网络实践引入包12345678import torch.nn as nnimport torch.nn.functional as Fimport numpy as npimport torchfrom torch.utils.data import Datasetimport pandas as pd%matplotlib inline  读入数据集onehot编码 iloc()函数  1">
<meta property="og:locale">
<meta property="og:image" content="https://pic.rmb.bdstatic.com/bjh/00a5fe17dfcfe501dd630e9b1d355c7c.jpeg">
<meta property="article:published_time" content="2022-08-20T09:23:24.635Z">
<meta property="article:modified_time" content="2022-08-22T12:25:19.646Z">
<meta property="article:author" content="蜡笔小金QAQ">
<meta property="article:tag" content="学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.rmb.bdstatic.com/bjh/00a5fe17dfcfe501dd630e9b1d355c7c.jpeg"><link rel="shortcut icon" href="https://pic.rmb.bdstatic.com/bjh/ebffc9cbcbd5601f0dd3ef8eceaee6de.jpeg"><link rel="canonical" href="http://example.com/2022/08/20/%E4%B8%87%E8%81%AA%E8%80%81%E5%B8%88%E9%A1%B9%E7%9B%AE/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习-pytorch-CNN网络实践',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-22 20:25:19'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="蜡笔小金QAQ的个人主页" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2022/07/04/kD1NT32f7QGVuIR.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">2</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">11</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.rmb.bdstatic.com/bjh/00a5fe17dfcfe501dd630e9b1d355c7c.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">蜡笔小金QAQ的个人主页</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习-pytorch-CNN网络实践</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-08-20T09:23:24.635Z" title="Created 2022-08-20 17:23:24">2022-08-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-08-22T12:25:19.646Z" title="Updated 2022-08-22 20:25:19">2022-08-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习-pytorch-CNN网络实践"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="CNN网络实践"><a href="#CNN网络实践" class="headerlink" title="CNN网络实践"></a>CNN网络实践</h1><h3 id="引入包"><a href="#引入包" class="headerlink" title="引入包"></a>引入包</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="读入数据集"><a href="#读入数据集" class="headerlink" title="读入数据集"></a>读入数据集</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/37471802">onehot编码</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39368111/article/details/110435536?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166089858416782184695575%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=166089858416782184695575&biz_id=0&spm=1018.2226.3001.4187">iloc()函数</a></p>
<p><img src="https://pic.rmb.bdstatic.com/bjh/9ed2a7ecf1645053aadfbf3ebf1a8eb3.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">targetDict = &#123;</span><br><span class="line">    <span class="number">109</span>: torch.Tensor([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">122</span>: torch.Tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">135</span>: torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">174</span>: torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">189</span>: torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">201</span>: torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">213</span>: torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">226</span>: torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">238</span>: torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">    <span class="number">97</span>: torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 定义了一个字典[label:onehot 编码]</span></span><br><span class="line"></span><br><span class="line">output2lable = [torch.Tensor([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">                torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(targetDict[<span class="number">109</span>])</span><br><span class="line"><span class="comment"># 定义一个数据集</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">bearDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 数据集演示 &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, csv_file, dim</span>):  <span class="comment"># dim为样本的维度</span></span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.df = pd.read_csv(csv_file)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.df)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># 取一行，一行的数目是[0,dim)</span></span><br><span class="line">        x = torch.tensor(</span><br><span class="line">            self.df.iloc[idx, <span class="number">0</span>:self.dim].values, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        x = x.view(<span class="number">1</span>, <span class="number">400</span>)</span><br><span class="line">        y = self.df.iloc[idx, <span class="number">2000</span>]</span><br><span class="line">        y = targetDict[y]</span><br><span class="line">        <span class="keyword">return</span> [x, y]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ds_demo = bearDataset(</span><br><span class="line">    <span class="string">&#x27;C:/Users/JINTIAN/Desktop/代码/PytorchCode/项目数据集/train.csv&#x27;</span>, <span class="number">400</span>)</span><br><span class="line">dl = torch.utils.data.DataLoader(</span><br><span class="line">    ds_demo, batch_size=<span class="number">1000</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)  <span class="comment"># 只训练10个</span></span><br><span class="line"><span class="comment"># dl是我们定义的一个数据加载函数，一次加载10个</span></span><br><span class="line">x1, y1 = ds_demo.__getitem__(<span class="number">11</span>)</span><br><span class="line"><span class="built_in">print</span>(x1)  <span class="comment"># 打印数据</span></span><br><span class="line"><span class="built_in">print</span>(x1.shape)</span><br><span class="line"><span class="built_in">print</span>(y1)  <span class="comment"># 标签</span></span><br><span class="line">idata = <span class="built_in">iter</span>(dl)</span><br><span class="line">x, y = <span class="built_in">next</span>(idata)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(y.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>tensor([[ 0.1037,  0.0555, -0.0096, -0.0547, -0.0682, -0.0524, -0.0179,  0.0238,
          0.0661,  0.0935,  0.0918,  0.0409, -0.0225, -0.0880, -0.1535, -0.1640,
         -0.1462, -0.0985, -0.0415, -0.0083,  0.0273,  0.0409,  0.0382,  0.0054,
         -0.0501, -0.0887, -0.1039, -0.0801, -0.0440, -0.0108,  0.0221,  0.0478,
          0.0822,  0.1081,  0.0855,  0.0257, -0.0321, -0.0657, -0.0611, -0.0365,
         -0.0177,  0.0048,  0.0332,  0.0684,  0.0951,  0.0903,  0.0463, -0.0211,
         -0.0734, -0.0895, -0.0724, -0.0401, -0.0040,  0.0463,  0.0989,  0.1277,
          0.1362,  0.1066,  0.0250, -0.0663, -0.1204, -0.1287, -0.0947, -0.0465,
         -0.0038,  0.0509,  0.0989,  0.1500,  0.1663,  0.1122,  0.0467, -0.0198,
         -0.0565, -0.0590, -0.0482, -0.0350, -0.0244,  0.0083,  0.0446,  0.0732,
          0.0565,  0.0046, -0.0486, -0.0862, -0.0665, -0.0342,  0.0002,  0.0323,
          0.0515,  0.0968,  0.1145,  0.0912,  0.0515, -0.0131, -0.0434, -0.0467,
         -0.0334,  0.0104,  0.0365,  0.0676,  0.0953,  0.1364,  0.1775,  0.1512,
          0.0962,  0.0169, -0.0463, -0.0680, -0.0793, -0.0597, -0.0271,  0.0136,
          0.0643,  0.0928,  0.0962,  0.0607,  0.0006, -0.0359, -0.0415, -0.0238,
         -0.0044,  0.0021,  0.0323,  0.0634,  0.0882,  0.1147,  0.0935,  0.0647,
          0.0344,  0.0188,  0.0265,  0.0117,  0.0042, -0.0017,  0.0192,  0.0640,
          0.0859,  0.0910,  0.0732,  0.0478,  0.0417,  0.0419,  0.0411,  0.0317,
          0.0119,  0.0119,  0.0311,  0.0668,  0.0718,  0.0446,  0.0169, -0.0148,
         -0.0154, -0.0169, -0.0165, -0.0125, -0.0008,  0.0509,  0.0933,  0.1318,
          0.1400,  0.1026,  0.0630,  0.0342,  0.0323,  0.0213,  0.0044,  0.0021,
          0.0225,  0.0584,  0.0857,  0.0966,  0.0695,  0.0321,  0.0094,  0.0119,
          0.0250,  0.0204,  0.0179,  0.0390,  0.0774,  0.1187,  0.1381,  0.1145,
          0.0638, -0.0031, -0.0365, -0.0307, -0.0238, -0.0052,  0.0136,  0.0613,
          0.1254,  0.1519,  0.1490,  0.1099,  0.0522,  0.0271,  0.0213,  0.0029,
         -0.0211, -0.0457, -0.0570, -0.0338,  0.0067,  0.0190, -0.0038, -0.0492,
         -0.0878, -0.1104, -0.1279, -0.1406, -0.1510, -0.1406, -0.1168, -0.0559,
         -0.0077, -0.0255, -0.0839, -0.1636, -0.1807, -0.1823, -0.1802, -0.1356,
         -0.1137, -0.0780, -0.0478, -0.0192, -0.0021, -0.0570, -0.0980, -0.1204,
         -0.1043, -0.0398, -0.0167, -0.0131, -0.0146, -0.0013,  0.0302,  0.0388,
          0.0227, -0.0255, -0.0524, -0.0469, -0.0273, -0.0058, -0.0148, -0.0184,
         -0.0104,  0.0244,  0.0695,  0.0862,  0.0899,  0.0613,  0.0492,  0.0726,
          0.0682,  0.0584,  0.0403,  0.0355,  0.0749,  0.1233,  0.1594,  0.1212,
          0.0584,  0.0407,  0.0494,  0.0784,  0.0993,  0.1118,  0.1064,  0.1043,
          0.1172,  0.1181,  0.0991,  0.0688,  0.0524,  0.0513,  0.0668,  0.0776,
          0.0505, -0.0002, -0.0273, -0.0150,  0.0255,  0.0611,  0.0609,  0.0355,
          0.0240,  0.0365,  0.0401,  0.0338, -0.0163, -0.0757, -0.0816, -0.0513,
          0.0058,  0.0409,  0.0478,  0.0330,  0.0202,  0.0267,  0.0046, -0.0426,
         -0.0941, -0.1218, -0.1024, -0.0576, -0.0211, -0.0152, -0.0240, -0.0184,
         -0.0038,  0.0050, -0.0259, -0.0953, -0.1602, -0.1844, -0.1462, -0.1020,
         -0.0720, -0.0471, -0.0188,  0.0332,  0.0736,  0.0755,  0.0067, -0.0897,
         -0.1396, -0.1375, -0.0895, -0.0421, -0.0071,  0.0060,  0.0081,  0.0302,
          0.0252, -0.0063, -0.0653, -0.1141, -0.1089, -0.0741, -0.0073,  0.0369,
          0.0515,  0.0640,  0.0722,  0.0859,  0.0471, -0.0319, -0.1164, -0.1748,
         -0.1467, -0.0870, -0.0113,  0.0478,  0.0786,  0.1218,  0.1323,  0.1256,
          0.0657, -0.0305, -0.0885, -0.1185, -0.0755, -0.0156,  0.0371,  0.0907,
          0.1133,  0.1556,  0.1792,  0.1675,  0.1118,  0.0211, -0.0350, -0.0553,
         -0.0229,  0.0181,  0.0294,  0.0486,  0.0826,  0.1285,  0.1287,  0.0832,
          0.0363, -0.0113, -0.0096,  0.0357,  0.0962,  0.1425,  0.1508,  0.1658,
          0.1727,  0.1621,  0.1273,  0.0713,  0.0288, -0.0054,  0.0021,  0.0309]])
torch.Size([1, 400])
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([[[-0.3764, -0.6076, -0.8242,  ...,  0.2153,  0.3919,  0.5388]],

        [[ 0.2809,  0.4340,  0.5613,  ..., -0.3155, -0.4678, -0.5692]],

        [[-1.0104, -0.8004, -0.4507,  ...,  0.5763,  0.4357,  0.2191]],

        ...,

        [[-0.0013, -0.0332, -0.0559,  ..., -0.1903, -0.0924,  0.0196]],

        [[ 0.0785,  0.0317,  0.0797,  ..., -0.1131, -0.2045, -0.1916]],

        [[-0.0096, -0.0338, -0.0355,  ..., -0.1273, -0.1494, -0.1273]]])
torch.Size([1000, 1, 400])
tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 1., 0.,  ..., 0., 0., 0.],
        [1., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 1., 0., 0.]])
torch.Size([1000, 10])
</code></pre>
<h3 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/liujh845633242/article/details/102668515">Conv1d()和Conv2d()区别</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yingluo54/article/details/122168364">conv1d详细用法</a></p>
<p><a target="_blank" rel="noopener" href="https://javajgs.com/archives/153549#:~:text=%E8%BE%93%E5%87%BA%E7%89%B9%E5%BE%81%E5%9B%BE%E5%B0%BA%E5%AF%B8%20%E6%9C%80%E5%90%8E%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%8B%E5%8D%B7%E7%A7%AF%E8%BE%93%E5%87%BA%E5%A4%A7%E5%B0%8F%3A%20N%20%3D%20%28W%20%E2%88%92%20F%20%2B,%E8%BE%93%E5%85%A5%E5%9B%BE%E7%89%87%E5%A4%A7%E5%B0%8F%20W%C3%97W%2C%20Filter%E5%A4%A7%E5%B0%8F%20F%C3%97F%2C%20%E6%AD%A5%E9%95%BF%20S%2C%20padding%E7%9A%84%E5%83%8F%E7%B4%A0%E6%95%B0%20P.">如何计算卷积网络的尺寸(公式)</a></p>
<p><img src="https://pic.rmb.bdstatic.com/bjh/35547f3a90d398bebc8e3aed0508a774.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()  <span class="comment"># 一个样本维度为400 维度：[10,1,1,400]</span></span><br><span class="line">        self.conv1 = nn.Conv1d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">11</span>,</span><br><span class="line">                               stride=<span class="number">4</span>)  <span class="comment"># 出来后此时：[10,64,1,98]</span></span><br><span class="line">        <span class="comment"># 1dpooling 维度算法参考https://blog.csdn.net/yingluo54/article/details/122168364</span></span><br><span class="line">        self.pool1 = nn.MaxPool1d(<span class="number">3</span>, stride=<span class="number">2</span>)  <span class="comment"># 出来后此时：[10,64,1,48]</span></span><br><span class="line">        self.conv2 = nn.Conv1d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>)  <span class="comment"># 出来后此时：[10,128,1,46]</span></span><br><span class="line">        self.pool2 = nn.MaxPool1d(<span class="number">3</span>, stride=<span class="number">2</span>)  <span class="comment"># 出来后此时：[10,128,1,22]</span></span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">22</span>*<span class="number">128</span>, <span class="number">22</span>*<span class="number">64</span>)  <span class="comment"># 从上边出来之后维度变成22</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">22</span>*<span class="number">64</span>, <span class="number">500</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">500</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.pool1(F.relu(self.conv1(x)))</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.pool2(F.relu(self.conv2(x)))</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">22</span>*<span class="number">128</span>)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="comment"># print(x.shape)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>Net(
  (conv1): Conv1d(1, 64, kernel_size=(11,), stride=(4,))
  (pool1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,))
  (pool2): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=2816, out_features=1408, bias=True)
  (fc2): Linear(in_features=1408, out_features=500, bias=True)
  (fc3): Linear(in_features=500, out_features=10, bias=True)
)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()  <span class="comment"># 损失函数</span></span><br><span class="line">optimizer = optim.Adam(net.parameters())  <span class="comment"># Adam训练器，用了发现比SGD好使</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h3><p><a target="_blank" rel="noopener" href="https://www.runoob.com/python/python-func-enumerate.html">enumerate()函数</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">loss_list = []</span><br><span class="line">x_list = []</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):  <span class="comment"># 多批次循环</span></span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span>  <span class="comment"># 每次重置0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># 获取输入</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 梯度置0</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 正向传播，反向传播，优化</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = nn.CrossEntropyLoss()</span><br><span class="line">        res = loss(outputs, labels)  <span class="comment"># 交叉熵损失函数</span></span><br><span class="line">        res.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印状态信息</span></span><br><span class="line">        running_loss += res.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:    <span class="comment"># 每2批次(1批次10个样本)打印一次</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.5f&#x27;</span> %</span><br><span class="line">                  (epoch + <span class="number">1</span>, i, running_loss / <span class="number">20</span>))</span><br><span class="line">            loss_list.append(running_loss / <span class="number">20</span>)</span><br><span class="line">            x_list.append(epoch*<span class="number">100</span>+i)</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[1,     0] loss: 0.11560
[2,     0] loss: 0.10816
[3,     0] loss: 0.10406
[4,     0] loss: 0.10030
[5,     0] loss: 0.09376
[6,     0] loss: 0.08903
[7,     0] loss: 0.08112
[8,     0] loss: 0.07515
[9,     0] loss: 0.06976
[10,     0] loss: 0.06235
[11,     0] loss: 0.06183
[12,     0] loss: 0.05548
[13,     0] loss: 0.05526
[14,     0] loss: 0.04942
[15,     0] loss: 0.04974
[16,     0] loss: 0.04542
[17,     0] loss: 0.04663
[18,     0] loss: 0.04146
[19,     0] loss: 0.04268
[20,     0] loss: 0.04244
[21,     0] loss: 0.03886
[22,     0] loss: 0.04085
[23,     0] loss: 0.03681
[24,     0] loss: 0.03655
[25,     0] loss: 0.03605
[26,     0] loss: 0.03463
[27,     0] loss: 0.03309
[28,     0] loss: 0.03342
[29,     0] loss: 0.03143
[30,     0] loss: 0.03075
[31,     0] loss: 0.02923
[32,     0] loss: 0.02879
[33,     0] loss: 0.02753
[34,     0] loss: 0.02645
[35,     0] loss: 0.02521
[36,     0] loss: 0.02453
[37,     0] loss: 0.02356
[38,     0] loss: 0.02244
[39,     0] loss: 0.02177
[40,     0] loss: 0.02063
[41,     0] loss: 0.01998
[42,     0] loss: 0.01928
[43,     0] loss: 0.01841
[44,     0] loss: 0.01762
[45,     0] loss: 0.01702
[46,     0] loss: 0.01625
[47,     0] loss: 0.01556
[48,     0] loss: 0.01509
[49,     0] loss: 0.01438
[50,     0] loss: 0.01373
[51,     0] loss: 0.01312
[52,     0] loss: 0.01256
[53,     0] loss: 0.01212
[54,     0] loss: 0.01175
[55,     0] loss: 0.01171
[56,     0] loss: 0.01280
[57,     0] loss: 0.01157
[58,     0] loss: 0.01030
[59,     0] loss: 0.00939
[60,     0] loss: 0.01008
[61,     0] loss: 0.01057
[62,     0] loss: 0.00840
[63,     0] loss: 0.00928
[64,     0] loss: 0.01041
[65,     0] loss: 0.00745
[66,     0] loss: 0.01025
[67,     0] loss: 0.01061
[68,     0] loss: 0.00787
[69,     0] loss: 0.01133
[70,     0] loss: 0.00717
[71,     0] loss: 0.00910
[72,     0] loss: 0.00646
[73,     0] loss: 0.00830
[74,     0] loss: 0.00706
[75,     0] loss: 0.00806
[76,     0] loss: 0.00628
[77,     0] loss: 0.00786
[78,     0] loss: 0.00644
[79,     0] loss: 0.01000
[80,     0] loss: 0.00878
[81,     0] loss: 0.01111
[82,     0] loss: 0.00684
[83,     0] loss: 0.01090
[84,     0] loss: 0.00600
[85,     0] loss: 0.00747
[86,     0] loss: 0.00538
[87,     0] loss: 0.00774
[88,     0] loss: 0.00504
[89,     0] loss: 0.00619
[90,     0] loss: 0.00443
[91,     0] loss: 0.00461
[92,     0] loss: 0.00471
[93,     0] loss: 0.00392
[94,     0] loss: 0.00499
[95,     0] loss: 0.00378
[96,     0] loss: 0.00412
[97,     0] loss: 0.00401
[98,     0] loss: 0.00354
[99,     0] loss: 0.00373
[100,     0] loss: 0.00302
Finished Training
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(x_list, loss_list)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="https://pic.rmb.bdstatic.com/bjh/d39e8b44779baeff785736f39a410c96.png" alt="png"></p>
<h3 id="开始测试"><a href="#开始测试" class="headerlink" title="开始测试"></a>开始测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">ds_test = bearDataset(</span><br><span class="line">    <span class="string">&#x27;C:/Users/JINTIAN/Desktop/代码/PytorchCode/项目数据集/test.csv&#x27;</span>, <span class="number">400</span>)</span><br><span class="line">dl_test = torch.utils.data.DataLoader(</span><br><span class="line">    ds_test, batch_size=<span class="number">1</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data, lable <span class="keyword">in</span> dl_test:</span><br><span class="line">        outputs = net(data)</span><br><span class="line">        <span class="comment"># print(outputs)</span></span><br><span class="line">        <span class="comment"># print(lable[0])</span></span><br><span class="line"></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># print(predicted.item())</span></span><br><span class="line">        p = output2lable[predicted.item()]</span><br><span class="line">        <span class="comment"># print(p)</span></span><br><span class="line"></span><br><span class="line">        total += lable.size(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span>(p.equal(lable[<span class="number">0</span>])):</span><br><span class="line">            correct = correct+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;total is &#x27;</span>, total)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy of the network: %d %%&#x27;</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>total is  300
Accuracy of the network: 93 %
</code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">蜡笔小金QAQ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/08/20/%E4%B8%87%E8%81%AA%E8%80%81%E5%B8%88%E9%A1%B9%E7%9B%AE/">http://example.com/2022/08/20/%E4%B8%87%E8%81%AA%E8%80%81%E5%B8%88%E9%A1%B9%E7%9B%AE/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a></div><div class="post_share"><div class="social-share" data-image="https://pic.rmb.bdstatic.com/bjh/00a5fe17dfcfe501dd630e9b1d355c7c.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/08/22/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/"><img class="prev-cover" src="https://pic.rmb.bdstatic.com/bjh/a71c596bf113260737725d665af9b3d8.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">深度学习-pytorch-批量归一化</div></div></a></div><div class="next-post pull-right"><a href="/2022/08/18/%E7%BB%8F%E5%85%B8CNN-VGG/"><img class="next-cover" src="https://pic.rmb.bdstatic.com/bjh/02b99c34f493d1bcc54a5ac4abbe5a68.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">深度学习-pytorch-经典CNN模型-VGG网络</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/08/05/2018HBCPC/" title="2018-HBCPC题解"><img class="cover" src="https://s2.loli.net/2022/08/05/etlrkYZvV9co3x7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-05</div><div class="title">2018-HBCPC题解</div></div></a></div><div><a href="/2022/08/22/CNN_NIN/" title="深度学习-pytorch-经典CNN模型-NIN和GoogLeNet"><img class="cover" src="https://pic.rmb.bdstatic.com/bjh/3a09bed7a9c0481f9c6a41c6bfa64f33.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-22</div><div class="title">深度学习-pytorch-经典CNN模型-NIN和GoogLeNet</div></div></a></div><div><a href="/2022/08/12/MLP/" title="深度学习-pytorch-MLP提高泛化"><img class="cover" src="https://s2.loli.net/2022/08/12/o9iUOrtGDa4gpH7.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-12</div><div class="title">深度学习-pytorch-MLP提高泛化</div></div></a></div><div><a href="/2022/08/22/CNN_ResNet/" title="深度学习-pytorch-经典CNN模型-ResNet"><img class="cover" src="https://pic.rmb.bdstatic.com/bjh/f893dcf5877974a1e319344bb020fa98.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-22</div><div class="title">深度学习-pytorch-经典CNN模型-ResNet</div></div></a></div><div><a href="/2022/08/10/Softmax%E5%9B%9E%E5%BD%92/" title="深度学习-pytorch-图片集与Softmax回归"><img class="cover" src="https://s2.loli.net/2022/08/10/7SNQucowEmrbxUW.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-10</div><div class="title">深度学习-pytorch-图片集与Softmax回归</div></div></a></div><div><a href="/2022/08/05/pytorch%E8%AF%AD%E6%B3%95/" title="深度学习-pytorch-张量tensor语法"><img class="cover" src="https://s2.loli.net/2022/08/05/OPdrDLG9f8q1kus.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-05</div><div class="title">深度学习-pytorch-张量tensor语法</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2022/07/04/kD1NT32f7QGVuIR.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">蜡笔小金QAQ</div><div class="author-info__description">你这代码保熟吗？</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">2</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">11</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/MrKiing-Jin"><i class="fab fa-github"></i><span>Github Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Mrkiing-Jin" target="_blank" title=""><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:labixiaojin666@163.com" target="_blank" title=""><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">扣扣号 : 1759212072 > _ < ( 评论模块已经实装，欢迎灌水！ (≧▽≦)  )</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#CNN%E7%BD%91%E7%BB%9C%E5%AE%9E%E8%B7%B5"><span class="toc-number">1.</span> <span class="toc-text">CNN网络实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E5%85%A5%E5%8C%85"><span class="toc-number">1.0.1.</span> <span class="toc-text">引入包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.0.2.</span> <span class="toc-text">读入数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">1.0.3.</span> <span class="toc-text">构建网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.0.4.</span> <span class="toc-text">开始训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%80%E5%A7%8B%E6%B5%8B%E8%AF%95"><span class="toc-number">1.0.5.</span> <span class="toc-text">开始测试</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/09/07/%E4%B8%87%E8%81%AA%E8%80%81%E5%B8%88%E9%A1%B9%E7%9B%AEGAP%E9%AD%94%E6%94%B9/" title="深度学习-pytorch-CNN网络实践(GAP)"><img src="https://s2.loli.net/2022/09/07/aRLdFl9Ot76SgWB.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度学习-pytorch-CNN网络实践(GAP)"/></a><div class="content"><a class="title" href="/2022/09/07/%E4%B8%87%E8%81%AA%E8%80%81%E5%B8%88%E9%A1%B9%E7%9B%AEGAP%E9%AD%94%E6%94%B9/" title="深度学习-pytorch-CNN网络实践(GAP)">深度学习-pytorch-CNN网络实践(GAP)</a><time datetime="2022-09-07T14:01:46.656Z" title="Created 2022-09-07 22:01:46">2022-09-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/31/matlab%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/" title="Matlab基本语法"><img src="https://s2.loli.net/2022/08/31/u5K2WDLNHfMceUt.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Matlab基本语法"/></a><div class="content"><a class="title" href="/2022/08/31/matlab%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/" title="Matlab基本语法">Matlab基本语法</a><time datetime="2022-08-31T02:17:06.103Z" title="Created 2022-08-31 10:17:06">2022-08-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/22/CNN_NIN/" title="深度学习-pytorch-经典CNN模型-NIN和GoogLeNet"><img src="https://pic.rmb.bdstatic.com/bjh/3a09bed7a9c0481f9c6a41c6bfa64f33.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度学习-pytorch-经典CNN模型-NIN和GoogLeNet"/></a><div class="content"><a class="title" href="/2022/08/22/CNN_NIN/" title="深度学习-pytorch-经典CNN模型-NIN和GoogLeNet">深度学习-pytorch-经典CNN模型-NIN和GoogLeNet</a><time datetime="2022-08-22T11:26:38.684Z" title="Created 2022-08-22 19:26:38">2022-08-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/22/CNN_ResNet/" title="深度学习-pytorch-经典CNN模型-ResNet"><img src="https://pic.rmb.bdstatic.com/bjh/f893dcf5877974a1e319344bb020fa98.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度学习-pytorch-经典CNN模型-ResNet"/></a><div class="content"><a class="title" href="/2022/08/22/CNN_ResNet/" title="深度学习-pytorch-经典CNN模型-ResNet">深度学习-pytorch-经典CNN模型-ResNet</a><time datetime="2022-08-22T11:26:33.713Z" title="Created 2022-08-22 19:26:33">2022-08-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/22/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/" title="深度学习-pytorch-批量归一化"><img src="https://pic.rmb.bdstatic.com/bjh/a71c596bf113260737725d665af9b3d8.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度学习-pytorch-批量归一化"/></a><div class="content"><a class="title" href="/2022/08/22/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/" title="深度学习-pytorch-批量归一化">深度学习-pytorch-批量归一化</a><time datetime="2022-08-22T11:26:26.888Z" title="Created 2022-08-22 19:26:26">2022-08-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 蜡笔小金QAQ</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">所有过往,皆为序章。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="Chat"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '87cce023bb99ffbb8aae',
      clientSecret: '9e197ddb2fc4f2877bd06446c036933417bea47d',
      repo: 'MrKiing-Jin.github.io',
      owner: 'MrKiing-Jin',
      admin: ['MrKiing-Jin'],
      id: 'ad94790c2eeed7757a93a9bd0efc6f72',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>